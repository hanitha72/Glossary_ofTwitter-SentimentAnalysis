{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linefinalar algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re\n",
    "\n",
    "#Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Sentiment.csv', encoding= 'latin1')\n",
    "# Keeping only the neccessary columns\n",
    "data = data[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_wordlist(review, remove_stopwords=False):\n",
    "    # 1. Removing html tags\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    # 2. Removing non-letter.\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \",review_text)\n",
    "    # 3. Converting to lower case and splitting\n",
    "    words = review_text.lower().split()\n",
    "    # 4. Optionally remove stopwords\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))     \n",
    "        words = [w for w in words if not w in stops]\n",
    "    \n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function splits a review into sentences\n",
    "def review_sentences(review, tokenizer, remove_stopwords=False):\n",
    "    # 1. Using nltk tokenizer\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    sentences = []\n",
    "    # 2. Loop for each sentence\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence)>0:\n",
    "            sentences.append(review_wordlist(raw_sentence,\\\n",
    "                                            remove_stopwords))\n",
    "\n",
    "    # This returns the list of lists\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "print(\"Parsing sentences from training set\")\n",
    "for review in data[\"text\"]:\n",
    "    sentences += review_sentences(review, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13871"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the built-in logging module\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 16:12:44,762 : INFO : collecting all words and their counts\n",
      "2020-07-23 16:12:44,764 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-07-23 16:12:44,845 : INFO : PROGRESS: at sentence #10000, processed 168882 words, keeping 18826 word types\n",
      "2020-07-23 16:12:44,874 : INFO : collected 20158 word types from a corpus of 228726 raw words and 13871 sentences\n",
      "2020-07-23 16:12:44,876 : INFO : Loading a fresh vocabulary\n",
      "2020-07-23 16:12:44,919 : INFO : effective_min_count=2 retains 8028 unique words (39% of original 20158, drops 12130)\n",
      "2020-07-23 16:12:44,921 : INFO : effective_min_count=2 leaves 216596 word corpus (94% of original 228726, drops 12130)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 16:12:44,989 : INFO : deleting the raw counts dictionary of 20158 items\n",
      "2020-07-23 16:12:44,991 : INFO : sample=0.001 downsamples 59 most-common words\n",
      "2020-07-23 16:12:44,992 : INFO : downsampling leaves estimated 168401 word corpus (77.7% of prior 216596)\n",
      "2020-07-23 16:12:45,041 : INFO : estimated required memory for 8028 words and 300 dimensions: 23281200 bytes\n",
      "2020-07-23 16:12:45,043 : INFO : resetting layer weights\n",
      "2020-07-23 16:12:49,238 : INFO : training model with 4 workers on 8028 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n",
      "2020-07-23 16:12:49,561 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-07-23 16:12:49,570 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-23 16:12:49,582 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-23 16:12:49,585 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-23 16:12:49,587 : INFO : EPOCH - 1 : training on 228726 raw words (168178 effective words) took 0.3s, 506780 effective words/s\n",
      "2020-07-23 16:12:49,907 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-07-23 16:12:49,918 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-23 16:12:49,921 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-23 16:12:49,934 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-23 16:12:49,936 : INFO : EPOCH - 2 : training on 228726 raw words (168222 effective words) took 0.3s, 509433 effective words/s\n",
      "2020-07-23 16:12:50,260 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-07-23 16:12:50,277 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-23 16:12:50,290 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-23 16:12:50,293 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-23 16:12:50,294 : INFO : EPOCH - 3 : training on 228726 raw words (168172 effective words) took 0.3s, 502798 effective words/s\n",
      "2020-07-23 16:12:50,636 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-07-23 16:12:50,647 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-23 16:12:50,653 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-23 16:12:50,655 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-23 16:12:50,656 : INFO : EPOCH - 4 : training on 228726 raw words (168477 effective words) took 0.3s, 506185 effective words/s\n",
      "2020-07-23 16:12:50,970 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-07-23 16:12:50,974 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-23 16:12:50,991 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-23 16:12:51,007 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-23 16:12:51,009 : INFO : EPOCH - 5 : training on 228726 raw words (168622 effective words) took 0.3s, 502857 effective words/s\n",
      "2020-07-23 16:12:51,010 : INFO : training on a 1143630 raw words (841671 effective words) took 1.8s, 475471 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# Creating the model and setting values for the various parameters\n",
    "num_features = 300  # Word vector dimensionality\n",
    "min_word_count = 2 # Minimum word count\n",
    "num_workers = 4     # Number of parallel threads\n",
    "context = 2       # Context window size\n",
    "downsampling = 1e-3 # (0.001) Downsample setting for frequent words\n",
    "\n",
    "# Initializing the train model\n",
    "from gensim.models import word2vec\n",
    "print(\"Training model....\")\n",
    "model = word2vec.Word2Vec(sentences,\\\n",
    "                          workers=num_workers,\\\n",
    "                          size=num_features,\\\n",
    "                          min_count=min_word_count,\\\n",
    "                          window=context,\n",
    "                          sample=downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 16:12:51,039 : INFO : precomputing L2-norms of word weight vectors\n",
      "2020-07-23 16:12:51,059 : INFO : saving Word2Vec object under second, separately None\n",
      "2020-07-23 16:12:51,061 : INFO : not storing attribute vectors_norm\n",
      "2020-07-23 16:12:51,063 : INFO : not storing attribute cum_table\n",
      "2020-07-23 16:12:51,846 : INFO : saved second\n"
     ]
    }
   ],
   "source": [
    "model.init_sims(replace=True)\n",
    "\n",
    "# Saving the model for later use. Can be loaded using Word2Vec.load()\n",
    "model_name = \"second\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanit\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8028, 300)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13871, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureVecMethod(words, model, num_features):\n",
    "    # Pre-initialising empty numpy array for speed\n",
    "    featureVec = np.zeros(num_features,dtype=\"float32\")\n",
    "    nwords = 0\n",
    "    \n",
    "    #Converting Index2Word which is a list to a set for better speed in the execution.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for word in  words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    \n",
    "    # Dividing the result by number of words to get average\n",
    "    featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating the average feature vector\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    counter = 0\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    for review in reviews:\n",
    "        # Printing a status message every 1000th review\n",
    "        if counter%1000 == 0:\n",
    "            print(\"Review %d of %d\"%(counter,len(reviews)))\n",
    "            \n",
    "        reviewFeatureVecs[counter] = featureVecMethod(review, model, num_features)\n",
    "        counter = counter+1\n",
    "        \n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          nancyleegrahn how did everyone feel about th...\n",
       "1          scottwalker didnt catch the full gopdebate l...\n",
       "2          tjmshow no mention of tamir rice and the gop...\n",
       "3          robgeorge that carly fiorina is trending  ho...\n",
       "4          danscavino gopdebate w realdonaldtrump deliv...\n",
       "                               ...                        \n",
       "13866      cappy_yarbrough love to see men who will nev...\n",
       "13867      georgehenryw who thought huckabee exceeded t...\n",
       "13868      lrihendry tedcruz as president i will always...\n",
       "13869      jrehling gopdebate donald trump says that he...\n",
       "13870      lrihendry tedcruz headed into the presidenti...\n",
       "Name: text, Length: 13871, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'] = data.sentiment.apply(lambda x: 1 if x=='Positive' else (0 if x == 'Negative' else 2 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13871,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9293,) (9293,)\n",
      "(4578,) (4578,)\n"
     ]
    }
   ],
   "source": [
    "Y = data.sentiment\n",
    "X = data.text\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating average feature vector for training set\n",
    "clean_train_reviews = []\n",
    "for review in X_train:\n",
    "    clean_train_reviews.append(review_wordlist(review, remove_stopwords=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 9293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanit\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 9293\n",
      "Review 2000 of 9293\n",
      "Review 3000 of 9293\n",
      "Review 4000 of 9293\n",
      "Review 5000 of 9293\n",
      "Review 6000 of 9293\n",
      "Review 7000 of 9293\n",
      "Review 8000 of 9293\n",
      "Review 9000 of 9293\n"
     ]
    }
   ],
   "source": [
    "trainDataVecs = getAvgFeatureVecs(clean_train_reviews, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00872234, -0.07955573, -0.03692256, ..., -0.0862991 ,\n",
       "        -0.00354794,  0.04749956],\n",
       "       [ 0.00807382, -0.08714921, -0.01523572, ..., -0.09979051,\n",
       "        -0.00198026,  0.00791041],\n",
       "       [ 0.00738994, -0.07814356, -0.0235209 , ..., -0.09021565,\n",
       "        -0.00170262,  0.02543346],\n",
       "       ...,\n",
       "       [ 0.01259313, -0.0736871 , -0.01388426, ..., -0.07025653,\n",
       "        -0.00461179,  0.03622225],\n",
       "       [ 0.00495181, -0.08288489, -0.00966207, ..., -0.07665171,\n",
       "        -0.00943881,  0.01935635],\n",
       "       [ 0.00228925, -0.07991865, -0.01605528, ..., -0.08495878,\n",
       "        -0.0052659 ,  0.03038369]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 4578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanit\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 4578\n",
      "Review 2000 of 4578\n",
      "Review 3000 of 4578\n",
      "Review 4000 of 4578\n"
     ]
    }
   ],
   "source": [
    "# Calculating average feature vactors for test set     \n",
    "clean_test_reviews = []\n",
    "for review in X_test:\n",
    "    clean_test_reviews.append(review_wordlist(review,remove_stopwords=True))\n",
    "    \n",
    "testDataVecs = getAvgFeatureVecs(clean_test_reviews, model, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest\n",
    "</h2 style= 'color:blue' >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a random forest classifier to the training data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting random forest to training data....\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting random forest to training data....\")    \n",
    "forest = forest.fit(trainDataVecs, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = forest.predict(trainDataVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = forest.predict(testDataVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      5684\n",
      "           1       0.90      0.90      0.90      1497\n",
      "           2       0.96      0.83      0.89      2112\n",
      "\n",
      "    accuracy                           0.93      9293\n",
      "   macro avg       0.93      0.90      0.92      9293\n",
      "weighted avg       0.93      0.93      0.93      9293\n",
      "\n",
      "F1 Score for training data:\n",
      "\n",
      "0.9156887724199017\n"
     ]
    }
   ],
   "source": [
    "# classification report for Train data:\n",
    "print(classification_report(y_true=Y_train, y_pred=train_preds))\n",
    "\n",
    "# F1 Score for Train data:\n",
    "print(\"F1 Score for training data:\\n\")\n",
    "print(f1_score(Y_train, train_preds, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.87      0.76      2809\n",
      "           1       0.47      0.27      0.34       739\n",
      "           2       0.42      0.25      0.31      1030\n",
      "\n",
      "    accuracy                           0.63      4578\n",
      "   macro avg       0.53      0.46      0.47      4578\n",
      "weighted avg       0.59      0.63      0.59      4578\n",
      "\n",
      "F1 Score for training data:\n",
      "\n",
      "0.4731724196339464\n"
     ]
    }
   ],
   "source": [
    "# classification report for test data:\n",
    "print(classification_report(y_true=Y_test, y_pred=test_preds))\n",
    "\n",
    "# F1 Score for Train data:\n",
    "print(\"F1 Score for training data:\\n\")\n",
    "print(f1_score(Y_test, test_preds, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Log_classifier = LogisticRegression()\n",
    "Log_classifier.fit(trainDataVecs, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "logtrainPreds = Log_classifier.predict(trainDataVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "logtestpreds = Log_classifier.predict(testDataVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for training data:\n",
      "0.3185689380984325\n",
      "------------\n",
      "\n",
      "F1 Score for training data:\n",
      "0.3167046916063004\n"
     ]
    }
   ],
   "source": [
    "# F1 Score for Train data:\n",
    "print(\"F1 Score for training data:\")\n",
    "print(f1_score(Y_train, logtrainPreds, average=\"macro\"))\n",
    "\n",
    "print('------------\\n')\n",
    "# F1 Score for Train data:\n",
    "print(\"F1 Score for training data:\")\n",
    "print(f1_score(Y_test, logtestpreds, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END\n"
     ]
    }
   ],
   "source": [
    "print(\"END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
